import json
import time
import asyncio
from typing import Dict, Optional, List
from dataclasses import dataclass
from abc import ABC, abstractmethod

from astrbot.api.event import AstrMessageEvent
from astrbot.api import logger


@dataclass
class CompletenessResult:
    """æ¶ˆæ¯å®Œæ•´æ€§åˆ¤æ–­ç»“æœ"""
    is_complete: bool = False
    confidence: float = 0.0
    reasoning: str = ""
    suggested_wait_time: float = 5.0  # å»ºè®®ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰


@dataclass
class MessageAggregation:
    """æ¶ˆæ¯èšåˆçŠ¶æ€"""
    user_id: str
    chat_id: str
    messages: List[AstrMessageEvent] = None
    aggregated_content: str = ""
    start_time: float = 0.0
    last_message_time: float = 0.0
    timer_task: Optional[asyncio.Task] = None
    is_waiting: bool = False

    def __post_init__(self):
        if self.messages is None:
            self.messages = []


class MessageProcessor(ABC):
    """æ¶ˆæ¯å¤„ç†å™¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def process_message(self, event: AstrMessageEvent) -> Optional[AstrMessageEvent]:
        """
        å¤„ç†æ¶ˆæ¯ï¼Œè¿”å›å¤„ç†åçš„æ¶ˆæ¯äº‹ä»¶
        è¿”å›Noneè¡¨ç¤ºæ¶ˆæ¯æ­£åœ¨èšåˆä¸­ï¼Œéœ€è¦ç­‰å¾…
        è¿”å›AstrMessageEventè¡¨ç¤ºæ¶ˆæ¯å·²å¤„ç†å®Œæ¯•ï¼Œå¯ä»¥è¿›è¡Œå¿ƒæµåˆ¤æ–­
        """
        pass


class DirectProcessor(MessageProcessor):
    """ç›´æ¥å¤„ç†å™¨ï¼ˆä¸è¿›è¡Œæ¶ˆæ¯èšåˆï¼‰"""
    
    async def process_message(self, event: AstrMessageEvent) -> Optional[AstrMessageEvent]:
        """ç›´æ¥è¿”å›åŸæ¶ˆæ¯ï¼Œä¸è¿›è¡Œä»»ä½•å¤„ç†"""
        return event


class AggregationProcessor(MessageProcessor):
    """æ¶ˆæ¯èšåˆå¤„ç†å™¨"""
    
    def __init__(self, config: dict, judge_provider_getter):
        self.config = config
        self.judge_provider_getter = judge_provider_getter  # è·å–åˆ¤æ–­æä¾›å•†çš„å‡½æ•°
        
        # èšåˆé…ç½®å‚æ•°
        self.max_wait_time = config.get("aggregation_max_wait_time", 12.0)
        self.confidence_threshold = config.get("aggregation_confidence_threshold", 0.7)
        self.judge_provider_name = config.get("judge_provider_name", "")
        
        # æ¶ˆæ¯èšåˆçŠ¶æ€ç®¡ç†
        self.aggregations: Dict[str, MessageAggregation] = {}
        
        logger.info(f"æ¶ˆæ¯èšåˆå¤„ç†å™¨å·²åˆå§‹åŒ– | æœ€å¤§ç­‰å¾…æ—¶é—´: {self.max_wait_time}ç§’ | ä¿¡å¿ƒé˜ˆå€¼: {self.confidence_threshold}")

    def _get_aggregation_key(self, event: AstrMessageEvent) -> str:
        """ç”Ÿæˆèšåˆé”®ï¼šç¾¤èŠID + ç”¨æˆ·ID"""
        return f"{event.unified_msg_origin}_{event.get_sender_id()}"

    async def judge_message_completeness(self, message_content: str, sender_name: str = "") -> CompletenessResult:
        """ç‹¬ç«‹åˆ¤æ–­æ¶ˆæ¯å®Œæ•´æ€§"""
        
        if not self.judge_provider_name:
            logger.debug("åˆ¤æ–­æä¾›å•†æœªé…ç½®ï¼Œé»˜è®¤è®¤ä¸ºæ¶ˆæ¯å®Œæ•´")
            return CompletenessResult(is_complete=True, reasoning="æä¾›å•†æœªé…ç½®ï¼Œé»˜è®¤å®Œæ•´")
        
        completeness_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¶ˆæ¯å®Œæ•´æ€§åˆ†æç³»ç»Ÿï¼Œè¯·åˆ¤æ–­ä»¥ä¸‹æ¶ˆæ¯æ˜¯å¦è¡¨è¾¾å®Œæ•´ã€‚

## å¾…åˆ†ææ¶ˆæ¯
å‘é€è€…: {sender_name}
å†…å®¹: {message_content}

## åˆ¤æ–­æ ‡å‡†
è¯·åˆ†æè¿™æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯ä¸€ä¸ªå®Œæ•´çš„è¡¨è¾¾ï¼š

**å®Œæ•´æ¶ˆæ¯çš„ç‰¹å¾**ï¼š
- è¡¨è¾¾äº†å®Œæ•´çš„æƒ³æ³•æˆ–è§‚ç‚¹
- è¯­æ³•ç»“æ„å®Œæ•´ï¼Œè¯­ä¹‰æ˜ç¡®
- ä¸å­˜åœ¨æ˜æ˜¾çš„"æœªå®Œå¾…ç»­"è¿¹è±¡

**ä¸å®Œæ•´æ¶ˆæ¯çš„å…¸å‹ç‰¹å¾**ï¼š
- è¿‡æ¸¡è¯å¼€å¤´ï¼š"ç­‰ç­‰"ã€"å¯¹äº†"ã€"è¿˜æœ‰"ã€"å¦å¤–"ã€"ç„¶å"
- æ˜æ˜¾çš„åˆ†æ®µè¡¨è¾¾ï¼š"æˆ‘è§‰å¾—..."ï¼ˆå¯èƒ½è¿˜æœ‰åç»­ï¼‰
- é—®é¢˜åªè¯´äº†ä¸€åŠ
- è¯­å¥è¢«æˆªæ–­æˆ–æœ‰æ˜æ˜¾çš„çœç•¥
- å¼•ç”¨ä½†æœªå®Œæ•´è¯´æ˜ï¼š"åˆšæ‰è¯´çš„é‚£ä¸ª..."
- è¡¨ç¤ºæ€è€ƒä¸­ï¼š"è®©æˆ‘æƒ³æƒ³"ã€"å—¯..."
- åˆ—ä¸¾å¼€å§‹ä½†æœªå®Œæˆï¼š"é¦–å…ˆ..."ã€"ç¬¬ä¸€..."

## ç­‰å¾…æ—¶é—´å»ºè®®
- å¦‚æœåˆ¤æ–­ä¸ºä¸å®Œæ•´ï¼Œå»ºè®®ç­‰å¾…æ—¶é—´ï¼ˆ3-10ç§’ï¼‰
- è€ƒè™‘æ¶ˆæ¯çš„ç´§æ€¥ç¨‹åº¦å’Œè¡¨è¾¾ä¹ æƒ¯

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "is_complete": true/false,
    "confidence": 0.0-1.0,
    "reasoning": "è¯¦ç»†åˆ†ææ¶ˆæ¯å®Œæ•´æ€§çš„åŸå› ",
    "suggested_wait_time": ç­‰å¾…ç§’æ•°
}}
"""

        try:
            judge_provider = self.judge_provider_getter()
            if not judge_provider:
                return CompletenessResult(is_complete=True, reasoning="æä¾›å•†è·å–å¤±è´¥ï¼Œé»˜è®¤å®Œæ•´")

            llm_response = await judge_provider.text_chat(prompt=completeness_prompt)
            content = llm_response.completion_text.strip()
            
            # è§£æJSONå“åº”
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            elif content.startswith("```"):
                content = content.replace("```", "").strip()

            result_data = json.loads(content)
            
            return CompletenessResult(
                is_complete=result_data.get("is_complete", True),
                confidence=result_data.get("confidence", 0.0),
                reasoning=result_data.get("reasoning", ""),
                suggested_wait_time=min(result_data.get("suggested_wait_time", 5.0), self.max_wait_time)
            )
            
        except Exception as e:
            logger.debug(f"å®Œæ•´æ€§åˆ¤æ–­å¤±è´¥: {e}")
            return CompletenessResult(is_complete=True, reasoning=f"åˆ¤æ–­å¤±è´¥ï¼Œé»˜è®¤å®Œæ•´: {str(e)}")

    async def process_message(self, event: AstrMessageEvent) -> Optional[AstrMessageEvent]:
        """å¤„ç†æ¶ˆæ¯ï¼Œå¯èƒ½è¿”å›èšåˆåçš„æ¶ˆæ¯æˆ–Noneï¼ˆè¡¨ç¤ºæ­£åœ¨ç­‰å¾…ï¼‰"""
        
        aggregation_key = self._get_aggregation_key(event)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿›è¡Œçš„èšåˆ
        if aggregation_key in self.aggregations and self.aggregations[aggregation_key].is_waiting:
            # æ­£åœ¨ç­‰å¾…ä¸­ï¼Œæ·»åŠ åˆ°èšåˆ
            return await self._handle_waiting_aggregation(event, aggregation_key)
        
        # æ–°æ¶ˆæ¯ï¼Œå…ˆåˆ¤æ–­å®Œæ•´æ€§
        completeness = await self.judge_message_completeness(event.message_str, event.get_sender_name())
        
        if not completeness.is_complete and completeness.confidence >= self.confidence_threshold:
            # ä¸å®Œæ•´ä¸”åˆ¤æ–­ä¿¡å¿ƒåº¦é«˜ï¼Œå¼€å§‹èšåˆç­‰å¾…
            logger.info(f"ğŸ”„ æ£€æµ‹åˆ°ä¸å®Œæ•´æ¶ˆæ¯ï¼Œå¼€å§‹èšåˆç­‰å¾… | {aggregation_key[:30]}... | ç­‰å¾…æ—¶é—´: {completeness.suggested_wait_time}ç§’ | ä¿¡å¿ƒåº¦: {completeness.confidence:.2f}")
            await self._start_message_aggregation(event, completeness.suggested_wait_time)
            return None  # è¿”å›Noneè¡¨ç¤ºæ­£åœ¨ç­‰å¾…
        
        # æ¶ˆæ¯å®Œæ•´ï¼Œç›´æ¥è¿”å›
        logger.debug(f"âœ… æ¶ˆæ¯å®Œæ•´ï¼Œç›´æ¥å¤„ç† | {aggregation_key[:30]}... | ä¿¡å¿ƒåº¦: {completeness.confidence:.2f}")
        return event

    async def _handle_waiting_aggregation(self, event: AstrMessageEvent, aggregation_key: str) -> Optional[AstrMessageEvent]:
        """å¤„ç†æ­£åœ¨ç­‰å¾…èšåˆçš„æ¶ˆæ¯"""
        
        aggregation = self.aggregations[aggregation_key]
        aggregation.messages.append(event)
        aggregation.last_message_time = time.time()
        aggregation.aggregated_content = " ".join([msg.message_str for msg in aggregation.messages])
        
        # é‡æ–°åˆ¤æ–­å®Œæ•´æ€§
        completeness = await self.judge_message_completeness(aggregation.aggregated_content, event.get_sender_name())
        
        if completeness.is_complete and completeness.confidence >= self.confidence_threshold:
            # ç°åœ¨å®Œæ•´äº†ï¼Œç«‹å³å¤„ç†
            logger.info(f"âœ… æ¶ˆæ¯èšåˆå®Œæˆ | {aggregation_key[:30]}... | æ¶ˆæ¯æ•°: {len(aggregation.messages)} | æœ€ç»ˆå†…å®¹: {aggregation.aggregated_content[:50]}...")
            return await self._finalize_aggregation(aggregation)
        else:
            # ä»ä¸å®Œæ•´ï¼Œç»§ç»­ç­‰å¾…ï¼ˆè®¡æ—¶å™¨ä¼šè‡ªåŠ¨å¤„ç†è¶…æ—¶ï¼‰
            logger.debug(f"â³ æ¶ˆæ¯ä»ä¸å®Œæ•´ï¼Œç»§ç»­ç­‰å¾… | {aggregation_key[:30]}... | ä¿¡å¿ƒåº¦: {completeness.confidence:.2f} | æ¶ˆæ¯æ•°: {len(aggregation.messages)}")
            return None

    async def _start_message_aggregation(self, event: AstrMessageEvent, wait_time: float):
        """å¼€å§‹æ¶ˆæ¯èšåˆç­‰å¾…"""
        
        key = self._get_aggregation_key(event)
        
        # åˆ›å»ºèšåˆçŠ¶æ€
        self.aggregations[key] = MessageAggregation(
            user_id=event.get_sender_id(),
            chat_id=event.unified_msg_origin,
            messages=[event],
            aggregated_content=event.message_str,
            start_time=time.time(),
            last_message_time=time.time(),
            is_waiting=True
        )
        
        # å¯åŠ¨ç­‰å¾…è®¡æ—¶å™¨
        self.aggregations[key].timer_task = asyncio.create_task(
            self._wait_for_completion(key, wait_time)
        )
        
        logger.debug(f"å¼€å§‹æ¶ˆæ¯èšåˆç­‰å¾… | {key[:30]}... | ç­‰å¾…æ—¶é—´: {wait_time}ç§’")

    async def _wait_for_completion(self, aggregation_key: str, wait_time: float):
        """ç­‰å¾…æ¶ˆæ¯èšåˆå®Œæˆ"""
        try:
            await asyncio.sleep(wait_time)
            
            # è¶…æ—¶åå¤„ç†èšåˆçš„æ¶ˆæ¯
            if aggregation_key in self.aggregations:
                aggregation = self.aggregations[aggregation_key]
                if aggregation.is_waiting:
                    logger.info(f"â° èšåˆç­‰å¾…è¶…æ—¶ï¼Œå¤„ç†èšåˆæ¶ˆæ¯ | {aggregation_key[:30]}... | æ¶ˆæ¯æ•°: {len(aggregation.messages)}")
                    # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç›´æ¥è°ƒç”¨å¤„ç†å‡½æ•°ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨å¼‚æ­¥ä»»åŠ¡ä¸­
                    # åªæ˜¯æ ‡è®°ä¸ºå®Œæˆï¼Œå®é™…å¤„ç†ç”±å¤–éƒ¨å¾ªç¯å¤„ç†
                    aggregation.is_waiting = False
                    
        except asyncio.CancelledError:
            logger.debug(f"èšåˆç­‰å¾…è¢«å–æ¶ˆ: {aggregation_key[:30]}...")

    async def _finalize_aggregation(self, aggregation: MessageAggregation) -> AstrMessageEvent:
        """å®Œæˆæ¶ˆæ¯èšåˆï¼Œè¿”å›èšåˆåçš„æ¶ˆæ¯äº‹ä»¶"""
        
        # å–æ¶ˆè®¡æ—¶å™¨
        if aggregation.timer_task and not aggregation.timer_task.done():
            aggregation.timer_task.cancel()
        
        # ä½¿ç”¨æœ€åä¸€æ¡æ¶ˆæ¯ä½œä¸ºåŸºç¡€ï¼Œä¿®æ”¹å…¶å†…å®¹ä¸ºèšåˆå†…å®¹
        final_event = aggregation.messages[-1]
        final_event.message_str = aggregation.aggregated_content
        
        # æ¸…ç†èšåˆçŠ¶æ€
        aggregation_key = self._get_aggregation_key(final_event)
        if aggregation_key in self.aggregations:
            del self.aggregations[aggregation_key]
        
        logger.info(f"ğŸ”— æ¶ˆæ¯èšåˆå·²å®Œæˆ | æœ€ç»ˆå†…å®¹: {aggregation.aggregated_content[:50]}...")
        return final_event

    def cleanup_expired_aggregations(self, max_age_seconds: float = 300):
        """æ¸…ç†è¿‡æœŸçš„èšåˆçŠ¶æ€ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰"""
        current_time = time.time()
        expired_keys = []
        
        for key, aggregation in self.aggregations.items():
            if current_time - aggregation.start_time > max_age_seconds:
                expired_keys.append(key)
                if aggregation.timer_task and not aggregation.timer_task.done():
                    aggregation.timer_task.cancel()
        
        for key in expired_keys:
            del self.aggregations[key]
            logger.debug(f"æ¸…ç†è¿‡æœŸèšåˆçŠ¶æ€: {key[:30]}...")

    def get_aggregation_status(self) -> dict:
        """è·å–èšåˆçŠ¶æ€ç»Ÿè®¡"""
        waiting_count = sum(1 for agg in self.aggregations.values() if agg.is_waiting)
        return {
            "total_aggregations": len(self.aggregations),
            "waiting_aggregations": waiting_count,
            "max_wait_time": self.max_wait_time,
            "confidence_threshold": self.confidence_threshold
        }
